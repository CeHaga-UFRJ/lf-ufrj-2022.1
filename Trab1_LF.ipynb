{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trab1 - LF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Trabalho 1 LF - Análise Lexica\n",
        "Trio Show foda"
      ],
      "metadata": {
        "id": "jWWlCauGBtoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria classe"
      ],
      "metadata": {
        "id": "l3RtUetEsnTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dfa:\n",
        "  \"\"\"\n",
        "    Uma classe usada para representar um autômato finito determinístico\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    s0 : int\n",
        "      Um número inteiro representando a posição do estado inicial na lista de estados\n",
        "    sf: list\n",
        "      Uma lista contendo todos os estados finais do autômato\n",
        "    q: list\n",
        "      Uma lista contendo todos os estados do autômato\n",
        "    alpha: list\n",
        "      Uma lista contendo o alfabeto do autômato\n",
        "    delta: list\n",
        "      Uma matriz contendo todas as transições do autômato\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    trans(self, state, ch)\n",
        "        Função que executa uma transição\n",
        "  \"\"\"\n",
        "  def __init__(self, s0, sf, q, alpha, delta):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    s0 : int\n",
        "      Um número inteiro representando a posição do estado inicial na lista de estados\n",
        "    sf: list\n",
        "      Uma lista contendo todos os estados finais do autômato\n",
        "    q: list\n",
        "      Uma lista contendo todos os estados do autômato\n",
        "    alpha: list\n",
        "      Uma lista contendo o alfabeto do autômato\n",
        "    delta: list\n",
        "      Uma matriz contendo todas as transições do autômato\n",
        "  \"\"\"\n",
        "    self.s0 = s0\n",
        "    self.sf = sf\n",
        "    self.q = q\n",
        "    self.alpha = alpha\n",
        "    self.delta = delta\n",
        "\n",
        "  def trans(self, state, ch):\n",
        "    \"\"\" Executa uma transição\n",
        "\n",
        "     Dado um estado e um símbolo retorna um estado correspondente à transição do autômato ou um erro caso nenhuma transição não exista \n",
        "     \n",
        "     Parameters\n",
        "     ----------\n",
        "        state : int\n",
        "            Um número inteiro representando a posição do estado na lista de estados\n",
        "        ch: str\n",
        "            Um símbolo\n",
        "     Raises\n",
        "     ------\n",
        "        ValueError\n",
        "           Se a transição com o estado e símbolo passado não exista\n",
        "     Returns\n",
        "     -------\n",
        "     int\n",
        "         Um número inteiro representando a posição do estado correspondente a transição na lista de estados\n",
        "\n",
        "    \"\"\"\n",
        "    try:\n",
        "      return self.delta[self.q.index(state)][self.alpha.index(ch)]\n",
        "    except ValueError:\n",
        "      return None"
      ],
      "metadata": {
        "id": "__93zkdJoTBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise Lexica de uma palavra\n",
        "A análise léxica consiste em, dada uma palavra e um autômato, separar as maiores subpalavras e determina a qual token elas pertencem. Isso é útil para compilação de código, pois assim é possível converter o texto escrito pela pessoa desenvolvedora a uma série de tokens mais fáceis de serem manipulados nos passos futuros.\n",
        "\n",
        "A ideia de separar a maior subpalavra vem naturalmente para quem já sabe programar, pois \"prin\" e \"printa\" são consideradas variáveis, enquanto \"print\" é o comando para escrever algo na tela."
      ],
      "metadata": {
        "id": "86X64P9PsqUA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iICUZE8oP4x"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Dada uma palavra e um automato, retorna se há uma subpalavra a partir do início que faça parte da linguagem\n",
        "\n",
        "word: Palavra string (ou lista de elementos) a ser verificado \n",
        "dfa: Automato finito deterministico da linguagem\n",
        "\n",
        "Retorna a maior subpalavra aceita a partir do início ou Exception caso não haja uma palavra\n",
        "\"\"\"\n",
        "\n",
        "def word_rec(word, dfa: Dfa):\n",
        "  # Inicializa o estado inicial, lexema e pilha\n",
        "  state = dfa.s0\n",
        "  lexema = \"\"\n",
        "  stack = []\n",
        "  \n",
        "  # Para cada elemento da palavra\n",
        "  for ch in word:\n",
        "    # Adiciona na subpalavra\n",
        "    lexema += ch\n",
        "    # Se chegou a um estado final limpa a pilha\n",
        "    if(state in dfa.sf):\n",
        "      stack = []\n",
        "    # Adiciona o estado na pilha\n",
        "    stack.append(state)\n",
        "    # Transiciona para o próximo estado \n",
        "    state = dfa.trans(state, ch)\n",
        "    # Se deu erro, para a leitura\n",
        "    if(state == None): break\n",
        "  \n",
        "  # Enquanto não chegou ao final e há elementos na pilha, volta até um estado final \n",
        "  while(state not in dfa.sf and len(stack) != 0):\n",
        "    state = stack.pop()\n",
        "    lexema = lexema[:-1]\n",
        "  \n",
        "  # Se chegou a um estado final, retorna a subpalavra\n",
        "  if(state in dfa.sf):\n",
        "    return lexema\n",
        "  \n",
        "  # Senao retorna erro\n",
        "  raise Exception(\"Invalid word\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostra exemplos"
      ],
      "metadata": {
        "id": "ECozR7QQszgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Palavras que começam com \", qualquer caracter, terminam com \""
      ],
      "metadata": {
        "id": "-YOcIHsmvJKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Entre com a palavra\n",
        "s0 = 1\n",
        "sf = [4]\n",
        "q = [1, 2, 3, 4]\n",
        "alpha = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','0','1','2','3','4','5','6','7','8','9','\"']\n",
        "delta = [\n",
        "  [None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,2],\n",
        "  [3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4],\n",
        "  [3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4],\n",
        "  [3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4]\n",
        "]\n",
        "\n",
        "dfa = Dfa(s0, sf, q, alpha, delta)\n",
        "\n",
        "word = \"\\\"\\\"\\\"a\" #@param {type:\"string\"}\n",
        "\n",
        "word_rec(word, dfa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X2BxU5JopR1x",
        "outputId": "165c2806-c46d-4e98-f226-7f339591d970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"\"\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Entre com a palavra\n",
        "s0 = 1\n",
        "sf = [10]\n",
        "q = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "alpha = ['0','1','2','3','4','5','6','7','8','9']\n",
        "delta = [\n",
        "  [None, None, None, None, None, None, None, None, None, 2],\n",
        "  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
        "  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
        "  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
        "  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6],\n",
        "  [7, 7, 7, 7, 7, 7, 7, 7, 7, 7],\n",
        "  [8, 8, 8, 8, 8, 8, 8, 8, 8, 8],\n",
        "  [9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
        "  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
        "  [None, None, None, None, None, None, None, None, None, None]\n",
        "]\n",
        "\n",
        "dfa = Dfa(s0, sf, q, alpha, delta)\n",
        "\n",
        "word = \"912345678a4534\" #@param {type:\"string\"}\n",
        "\n",
        "word_rec(word, dfa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tfYcxOM6xFLX",
        "outputId": "c5acbf49-6fd5-40ad-85fd-dad6728416fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'912345678'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}
